{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "256c7997-3f9e-4b5f-bb4d-bda5ec852e8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Speeding up LLM inference by using model quantization in Databricks\n",
    "\n",
    "This notebook serves as supplementary material to the [blog article link].\n",
    "It includes the code snippets referenced in the blog post, providing a hands-on opportunity to explore and implement the concepts discussed.\n",
    "\n",
    "This notebook is an extension of the [Fine-tuning your LLM with Databricks Mosaic AI](https://notebooks.databricks.com/demos/llm-fine-tuning/index.html#) demo. It also leverages the acompanying NER dataset from the demo, which you can install by running:\n",
    "\n",
    "```\n",
    "\n",
    "%pip install dbdemos\n",
    "\n",
    "import dbdemos\n",
    "dbdemos.install('llm-fine-tuning')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7706dd8-5baf-4a59-bf0a-f14a470d7dbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5d78b40-8bd1-4b87-8a0c-ee26627a7406",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U databricks-genai databricks-sdk transformers optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a07d1a8-b227-4a00-8cb7-d8766a0d9694",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# install AutoGPTQ from source (required for GPU config)\n",
    "!mkdir /local_disk0/AutoGPTQ\n",
    "!git clone https://github.com/PanQiWei/AutoGPTQ.git /local_disk0/AutoGPTQ\n",
    "!pip install -vvv -e /local_disk0/AutoGPTQ/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "060d2c3e-07b0-4756-b74f-c4594c89fc51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# restart the Python kernel to pick up the new libraries\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dd96cd7-4276-430e-971b-ba2839f53fdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Build our prompt template to extract entities\n",
    "\n",
    "You need to set the `catalog` and `schema` variables to point to the locations of the NER tables (from the `llm-fine-tuning` demo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0c946ee-9f6d-4351-aa99-2114406a702f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"...\"\n",
    "schema = \"...\"\n",
    "spark.sql(f\"use catalog {catalog}\")\n",
    "spark.sql(f\"use schema {schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d30a533-a2a2-4b86-96ce-7e91e9fd6866",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "System Prompt Definition"
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "### INSTRUCTIONS:\n",
    "You are a medical and pharmaceutical expert. Your task is to identify pharmaceutical drug names from the provided input and list them accurately. Follow these guidelines:\n",
    "\n",
    "1. Do not add any commentary or repeat the instructions.\n",
    "2. Extract the names of pharmaceutical drugs mentioned.\n",
    "3. Place the extracted names in a Python list format. Ensure the names are enclosed in square brackets and separated by commas and wrapped in double quotes, e.g. [\"paracetamol\", \"ibuprofen\"].\n",
    "4. Maintain the order in which the drug names appear in the input.\n",
    "5. Do not add any text before or after the list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71fae0c8-a855-4263-8e64-ba82b7d9cbb8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Utility Functions"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import pandas_udf, to_json\n",
    "\n",
    "# Extract the json array from the text, removing potential noise\n",
    "def extract_json_array(text):\n",
    "    # Use regex to find a JSON array within the text\n",
    "    match = re.search(r\"(\\[.*?\\])\", text)\n",
    "    if match:\n",
    "        try:\n",
    "            parsed = json.loads(match.group(0))\n",
    "            if isinstance(parsed, list):\n",
    "                return parsed\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    return []\n",
    "\n",
    "\n",
    "def get_current_cluster_id():\n",
    "    import json\n",
    "\n",
    "    return json.loads(\n",
    "        dbutils.notebook.entry_point.getDbutils().notebook().getContext().safeToJson()\n",
    "    )[\"attributes\"][\"clusterId\"]\n",
    "\n",
    "\n",
    "@pandas_udf(\"array<struct<role:string, content:string>>\")\n",
    "def create_train_conv(sentence: pd.Series, entities: pd.Series) -> pd.Series:\n",
    "    def build_message(s, e):\n",
    "        # Default behavior with system prompt\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": str(s)},\n",
    "            {\"role\": \"assistant\", \"content\": e},\n",
    "        ]\n",
    "\n",
    "    # Apply build_message to each pair of sentence and entity\n",
    "    return pd.Series([build_message(s, e) for s, e in zip(sentence, entities)])\n",
    "\n",
    "\n",
    "def create_test_conv(df):\n",
    "    return df.apply(\n",
    "        lambda row: [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": row[\"sentence\"]},\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_entities(df, model):\n",
    "    model.generation_config.update(temperature=0.1, max_new_tokens=100, max_length=None)\n",
    "    results = model.predict(list(create_test_conv(df)))\n",
    "    predictions = [p[0][\"generated_text\"][-1][\"content\"] for p in results]\n",
    "    cleaned_predictions = [extract_json_array(p) for p in predictions]\n",
    "    return predictions, cleaned_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6edfaac1-ca83-4d76-922e-2863150e49bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_precision_recall(prediction, ground_truth):\n",
    "    prediction_set = set([str(drug).lower() for drug in prediction])\n",
    "    ground_truth_set = set([str(drug).lower() for drug in ground_truth])\n",
    "    all_elements = prediction_set.union(ground_truth_set)\n",
    "\n",
    "    # Convert sets to binary lists\n",
    "    prediction_binary = [int(element in prediction_set) for element in all_elements]\n",
    "    ground_truth_binary = [int(element in ground_truth_set) for element in all_elements]\n",
    "\n",
    "    precision = precision_score(ground_truth_binary, prediction_binary)\n",
    "    recall = recall_score(ground_truth_binary, prediction_binary)\n",
    "    f1 = f1_score(ground_truth_binary, prediction_binary)\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c17311a5-92b8-423f-87de-ce7baf9349c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def precision_recall_series(column_name):\n",
    "    def inner(row):\n",
    "        precision, recall, f1 = compute_precision_recall(\n",
    "            row[column_name], row[\"human_annotated_entities\"]\n",
    "        )\n",
    "        return pd.Series([precision, recall, f1], index=[\"precision\", \"recall\", \"f1\"])\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "201d47e6-12ee-45f1-8fe1-a0b2e0e23bc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9db4840-fbc3-455f-8c47-252b12fb7fee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "hf_dataset_name = \"allenai/drug-combo-extraction\"\n",
    "\n",
    "# Specify a cache directory (e.g. Unity Catalog volume)\n",
    "cache_dir = \"...\"\n",
    "\n",
    "dataset_test = load_dataset(hf_dataset_name, split=\"test\", cache_dir=cache_dir)\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame\n",
    "df_test = pd.DataFrame(dataset_test)\n",
    "\n",
    "# Extract the entities from the spans\n",
    "df_test[\"human_annotated_entities\"] = df_test[\"spans\"].apply(\n",
    "    lambda spans: [span[\"text\"] for span in spans]\n",
    ")\n",
    "\n",
    "df_test = df_test[[\"sentence\", \"human_annotated_entities\"]]\n",
    "\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0417e8c9-fcc4-4d56-9297-84325dad9fa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Load the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c84560ae-28db-4791-b8d9-4d5933ccee59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6ebb123-ef78-4574-af30-b4754821e6a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_model_name = \"llama_v3_2_1b_instruct\"\n",
    "base_model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "model_version = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "282f5ba4-b6ad-460e-a15c-b7acfa9dfbc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_uri = f\"models:/system.ai.{base_model_name}/{model_version}\"\n",
    "mdl_pipe = mlflow.transformers.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37c92f8a-61d6-41f3-b2f5-2638b618ce6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Extract entities with the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2688738-f082-459c-90d7-d7acf86cbe8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Taking only a few examples from test set to collect benchmark metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_validation, df_test_small = train_test_split(df_test, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed513252-0c7c-4798-a7e6-869bdf700f89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions, cleaned_predictions = extract_entities(df_test_small, mdl_pipe)\n",
    "df_test_small[\"baseline_predictions\"] = predictions\n",
    "df_test_small[\"baseline_predictions_cleaned\"] = cleaned_predictions\n",
    "display(\n",
    "    df_test_small[\n",
    "        [\"sentence\", \"baseline_predictions_cleaned\", \"human_annotated_entities\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0a37781-eca7-4b8f-9623-6324072d0996",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluating our baseline model\n",
    "\n",
    "We can see that our model is extracting a good number of entities, but it also occasionally adds some random text after/before the inferences.\n",
    "\n",
    "### Precision & recall for entity extraction\n",
    "\n",
    "We'll benchmark our model by computing its accuracy and recall. Let's compute these value for each sentence in our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "232f6af0-c7ed-4a34-a569-a46df06b8467",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_test_small[\n",
    "    [\"baseline_precision\", \"baseline_recall\", \"baseline_f1\"]\n",
    "] = df_test_small.apply(precision_recall_series(\"baseline_predictions_cleaned\"), axis=1)\n",
    "df_test_small[[\"baseline_precision\", \"baseline_recall\", \"baseline_f1\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78da1840-76b5-49ed-95ee-e533a35f91dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Fine-tuning our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7cdda70d-fc8f-4e9d-ad6e-db979ab30352",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Fine tuning data preparation\n",
    "\n",
    "Before fine-tuning, we need to apply our prompt template to the samples in the training dataset, and extract the ground truth list of drugs into the list format we are targeting.\n",
    "\n",
    "We'll save this to our Databricks catalog as a table. Usually, this is part of a full Data Engineering pipeline.\n",
    "\n",
    "Remember that this step is key for your Fine Tuning, make sure your training dataset is of high quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73e6bf5f-832a-4209-abde-c9909d1f7e54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset_train = load_dataset(hf_dataset_name, split=\"train\", cache_dir=cache_dir)\n",
    "df_train = pd.DataFrame(dataset_train)\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame\n",
    "df_train = pd.DataFrame(df_train)\n",
    "\n",
    "# Extract the entities from the spans\n",
    "df_train[\"human_annotated_entities\"] = df_train[\"spans\"].apply(\n",
    "    lambda spans: [span[\"text\"] for span in spans]\n",
    ")\n",
    "\n",
    "df_train = df_train[[\"sentence\", \"human_annotated_entities\"]]\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaeb2838-53f9-4b40-a493-30dfaaa85392",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf, to_json\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_train is defined and correctly formatted as a Spark DataFrame with columns 'sentence' and 'entities'\n",
    "training_dataset = spark.createDataFrame(df_train).withColumn(\n",
    "    \"human_annotated_entities\", to_json(\"human_annotated_entities\")\n",
    ")\n",
    "\n",
    "# Apply UDF, write to a table, and display it\n",
    "training_dataset.select(\n",
    "    create_train_conv(\"sentence\", \"human_annotated_entities\").alias(\"messages\")\n",
    ").write.mode(\"overwrite\").saveAsTable(\"ner_chat_completion_training_dataset\")\n",
    "display(spark.table(\"ner_chat_completion_training_dataset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "824bdc6c-4026-4434-84fb-270e18f240dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Prepare the eval dataset as well. We have the data available in `df_validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "984b025f-d602-4c3e-a222-617f7a527287",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_dataset = spark.createDataFrame(df_validation).withColumn(\n",
    "    \"human_annotated_entities\", to_json(\"human_annotated_entities\")\n",
    ")\n",
    "\n",
    "# Apply UDF, write to a table, and display it\n",
    "eval_dataset.select(\n",
    "    create_train_conv(\"sentence\", \"human_annotated_entities\").alias(\"messages\")\n",
    ").write.mode(\"overwrite\").saveAsTable(\"ner_chat_completion_eval_dataset\")\n",
    "display(spark.table(\"ner_chat_completion_eval_dataset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5441111b-804f-4a97-ade0-bbcbf7131585",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Fine-tuning\n",
    "Once our data is ready, we can just call the fine tuning API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c8e1c25-2420-4813-ba0e-e8843718a2dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.model_training import foundation_model as fm\n",
    "\n",
    "# Change the model name back to drug_extraction_ft after testing\n",
    "registered_model_name = f\"{catalog}.{schema}.drug_extraction_ft_\" + re.sub(\n",
    "    r\"[^a-zA-Z0-9]\", \"_\", str(base_model_name).lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9679dcb4-4260-4829-ae37-6ac7a2498028",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the fine tuning run\n",
    "run = fm.create(\n",
    "    data_prep_cluster_id=get_current_cluster_id(),  # Required if you are using delta tables as training data source. This is the cluster id that we want to use for our data prep job. See ./_resources for more details\n",
    "    model=base_model_path,\n",
    "    train_data_path=f\"{catalog}.{schema}.ner_chat_completion_training_dataset\",\n",
    "    eval_data_path=f\"{catalog}.{schema}.ner_chat_completion_eval_dataset\",\n",
    "    task_type=\"CHAT_COMPLETION\",\n",
    "    register_to=registered_model_name,\n",
    "    training_duration=\"10ep\",  # Duration of the finetuning run, 10 epochs only to make it fast for the demo. Check the training run metrics to know when to stop it (when it reaches a plateau)\n",
    ")\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8217b002-ce37-4df6-8b57-0e1171ecc9cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Retrieve the fine tuned model and rerun the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d455965c-618e-4143-8f57-4a3b02fed328",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ft_mdl_pipe = mlflow.transformers.load_model(f\"models:/{registered_model_name}/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c459096-f024-400f-9523-09c273c03828",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions, cleaned_predictions = extract_entities(df_test_small, ft_mdl_pipe)\n",
    "df_test_small[\"ft_predictions\"] = predictions\n",
    "df_test_small[\"ft_predictions_cleaned\"] = cleaned_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1521480-6bd4-4d3d-91bb-9cfd3671bf80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_test_small[[\"ft_precision\", \"ft_recall\", \"ft_f1\"]] = df_test_small.apply(\n",
    "    precision_recall_series(\"ft_predictions_cleaned\"), axis=1\n",
    ")\n",
    "df_test_small[[\"ft_precision\", \"ft_recall\", \"ft_f1\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9974351-526a-4697-bc04-8c26cd11802e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Quantize the fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1718bbb-98a0-49d2-a81b-d5cee5bcd7c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Download the artifacts of the specified registered model version from MLflow\n",
    "local_path = mlflow.artifacts.download_artifacts(f\"models:/{registered_model_name}/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "330dce09-5f9e-441a-bfa9-7469825266d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextGenerationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d1428bb-6657-4478-a63c-9c8cf73b4cfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the tokenizer and quantized model from the specified local path, load model to the GPU\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    local_path + \"components/tokenizer\", trust_remote_code=True\n",
    ")\n",
    "\n",
    "qnt_config = BaseQuantizeConfig(bits=4, group_size=128)\n",
    "model = AutoGPTQForCausalLM.from_pretrained(\n",
    "    local_path + \"model\", quantize_config=qnt_config\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22c38d76-d78a-41d5-828e-126c97cfd108",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a calibration dataset by extracting and tokenizing text messages from the fine tuning training data\n",
    "\n",
    "calibration_json = (\n",
    "    spark.table(\"ner_chat_completion_training_dataset\").limit(3).toJSON().collect()\n",
    ")\n",
    "calibration_texts = [json.loads(c)[\"messages\"] for c in calibration_json]\n",
    "\n",
    "examples = []\n",
    "for item in calibration_texts:\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        item, tokenize=False, add_generation_prompt=False\n",
    "    )\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    examples.append(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0ced8d3-1094-4428-bb94-84e83c033b38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Quantize the model\n",
    "model.quantize(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ff2c34e-6fa2-418a-830e-b0b481c74cd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!rm -r /local_disk0/quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d04a95a4-e203-4339-86e8-bb99f314b756",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!mkdir /local_disk0/quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63559a0e-f518-4d0a-b881-b76c90b6b611",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the quantized model to the local disk\n",
    "model.save_quantized(\"/local_disk0/quantized/\", use_safetensors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93625f39-a060-4dcd-9185-a99c85a6814b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Retrieve the quantized model and rerun the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c241b751-790e-4754-8b4c-81270955fc0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ea577a7-b958-48c4-b9aa-6bf6622eed97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "quantized_model = AutoGPTQForCausalLM.from_quantized(\"/local_disk0/quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4983bcec-0865-4e57-9ab2-e15efc27dfca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ft_qnt_mdl_pipe = TextGenerationPipeline(\n",
    "    model=quantized_model.model, tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3db00959-c27c-4803-9af7-01c9c7bae046",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions, cleaned_predictions = extract_entities(df_test_small, ft_qnt_mdl_pipe)\n",
    "df_test_small[\"qt_predictions\"] = predictions\n",
    "df_test_small[\"qt_predictions_cleaned\"] = cleaned_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23327f0e-7bc3-41ed-9610-50021e489854",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_test_small[[\"qt_precision\", \"qt_recall\", \"qt_f1\"]] = df_test_small.apply(\n",
    "    precision_recall_series(\"qt_predictions_cleaned\"), axis=1\n",
    ")\n",
    "df_test_small[[\"qt_precision\", \"qt_recall\", \"qt_f1\"]].describe()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3819540237215317,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Model Quantization Example",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}